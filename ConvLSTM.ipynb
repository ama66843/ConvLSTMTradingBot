{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras import callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "import statistics\n",
    "import time \n",
    "import os\n",
    "import json\n",
    "import yfinance as yf\n",
    "from keras.models import model_from_json\n",
    "import requests\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes data from yfinance\n",
    "#reshapes into form (n_seq, 1, n_steps, n_features)\n",
    "def data_setup(symbol,data_len,seq_len):\n",
    "    end = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    start = datetime.datetime.strptime(end, '%Y-%m-%d') - datetime.timedelta(days=(data_len/0.463))\n",
    "    orig_dataset = yf.download(symbol,start,end)\n",
    "    close = orig_dataset['Close'].values\n",
    "    open_ = orig_dataset['Open'].values\n",
    "    high = orig_dataset['High'].values\n",
    "    low = orig_dataset['Low'].values\n",
    "    dataset,minmax = normalize_data(orig_dataset)\n",
    "    cols = dataset.columns.tolist()\n",
    "    data_seq = list()\n",
    "    for i in range(len(cols)):\n",
    "        if cols[i] < 4:\n",
    "            data_seq.append(dataset[cols[i]].values)\n",
    "            data_seq[i] = data_seq[i].reshape((len(data_seq[i]), 1))\n",
    "    data = hstack(data_seq)\n",
    "    n_steps = seq_len\n",
    "    X, y = split_sequences(data, n_steps)\n",
    "    n_features = X.shape[2]\n",
    "    n_seq = len(X)\n",
    "    n_steps = seq_len\n",
    "    print(X.shape)\n",
    "    X = X.reshape((n_seq,1, n_steps, n_features))\n",
    "    true_y = []\n",
    "    for i in range(len(y)):\n",
    "        true_y.append([y[i][0],y[i][1]])\n",
    "    return X,array(true_y),n_features,minmax,n_steps,close,open_,high,low, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "(2183, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "X,y,n_features,minmax,n_steps,close,open_,high,low,data = data_setup('AAPL',1500,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2184, 1, 50, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#form (n_seq, 1, n_steps, n_features)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "        X, y = list(), list()\n",
    "        for i in range(len(sequences)):\n",
    "            end_ix = i + n_steps\n",
    "            if end_ix > len(sequences)-1:\n",
    "                break\n",
    "            seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "        return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xarr, yarr = split_sequences(,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized to max/min of each sequence instead of to the first element in that sequence \n",
    "def normalize_data(dataset):\n",
    "        cols = dataset.columns.tolist()\n",
    "        col_name = [0]*len(cols)\n",
    "        for i in range(len(cols)):\n",
    "            col_name[i] = i\n",
    "        dataset.columns = col_name\n",
    "        dtypes = dataset.dtypes.tolist()\n",
    "#         orig_answers = dataset[attr_row_predict].values\n",
    "        minmax = list()\n",
    "        for column in dataset:\n",
    "            dataset = dataset.astype({column: 'float32'})\n",
    "        for i in range(len(cols)):\n",
    "            col_values = dataset[col_name[i]]\n",
    "            value_min = min(col_values)\n",
    "            value_max = max(col_values)\n",
    "            minmax.append([value_min, value_max])\n",
    "        for column in dataset:\n",
    "            values = dataset[column].values\n",
    "            for i in range(len(values)):\n",
    "                values[i] = (values[i] - minmax[column][0]) / (minmax[column][1] - minmax[column][0])\n",
    "            dataset[column] = values\n",
    "        dataset[column] = values\n",
    "        return dataset,minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enviroment_setup(X,y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = enviroment_setup(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_steps,n_features,optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=8, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvMod=initialize_network(50,4,'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train,y_train,model,epochs):\n",
    "    dirx = './ConvModel'\n",
    "    os.chdir(dirx)\n",
    "    h5='Stocks'+'_best_model'+'.h5'\n",
    "    checkpoint = callbacks.ModelCheckpoint(h5, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "    earlystop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=epochs * 1/4, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "    callback = [earlystop,checkpoint] \n",
    "    json = 'Stocks'+'_best_model'+'.json'\n",
    "    model_json = model.to_json()\n",
    "    with open(json, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=len(X_train)//4, verbose=2,validation_split = 0.3, callbacks = callback)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/300\n",
      "3/3 - 0s - loss: 0.0531 - val_loss: 0.0098\n",
      "Epoch 2/300\n",
      "3/3 - 0s - loss: 0.0076 - val_loss: 0.0170\n",
      "Epoch 3/300\n",
      "3/3 - 0s - loss: 0.0130 - val_loss: 0.0017\n",
      "Epoch 4/300\n",
      "3/3 - 0s - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 5/300\n",
      "3/3 - 0s - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 6/300\n",
      "3/3 - 0s - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 7/300\n",
      "3/3 - 0s - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 8/300\n",
      "3/3 - 0s - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 9/300\n",
      "3/3 - 0s - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 10/300\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 11/300\n",
      "3/3 - 0s - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 12/300\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 13/300\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 14/300\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.8210e-04\n",
      "Epoch 15/300\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.4352e-04\n",
      "Epoch 16/300\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.1072e-04\n",
      "Epoch 17/300\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8236e-04\n",
      "Epoch 18/300\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.5491e-04\n",
      "Epoch 19/300\n",
      "3/3 - 0s - loss: 9.9275e-04 - val_loss: 8.0596e-04\n",
      "Epoch 20/300\n",
      "3/3 - 0s - loss: 9.7499e-04 - val_loss: 8.0906e-04\n",
      "Epoch 21/300\n",
      "3/3 - 0s - loss: 9.1945e-04 - val_loss: 7.7484e-04\n",
      "Epoch 22/300\n",
      "3/3 - 0s - loss: 9.4460e-04 - val_loss: 7.5676e-04\n",
      "Epoch 23/300\n",
      "3/3 - 0s - loss: 8.7627e-04 - val_loss: 7.7806e-04\n",
      "Epoch 24/300\n",
      "3/3 - 0s - loss: 8.7581e-04 - val_loss: 7.1298e-04\n",
      "Epoch 25/300\n",
      "3/3 - 0s - loss: 8.4184e-04 - val_loss: 7.0117e-04\n",
      "Epoch 26/300\n",
      "3/3 - 0s - loss: 8.5114e-04 - val_loss: 6.8149e-04\n",
      "Epoch 27/300\n",
      "3/3 - 0s - loss: 8.1090e-04 - val_loss: 6.8633e-04\n",
      "Epoch 28/300\n",
      "3/3 - 0s - loss: 7.7677e-04 - val_loss: 6.8432e-04\n",
      "Epoch 29/300\n",
      "3/3 - 0s - loss: 7.4523e-04 - val_loss: 6.4222e-04\n",
      "Epoch 30/300\n",
      "3/3 - 0s - loss: 7.0719e-04 - val_loss: 6.4297e-04\n",
      "Epoch 31/300\n",
      "3/3 - 0s - loss: 6.9168e-04 - val_loss: 6.0348e-04\n",
      "Epoch 32/300\n",
      "3/3 - 0s - loss: 6.5494e-04 - val_loss: 5.9048e-04\n",
      "Epoch 33/300\n",
      "3/3 - 0s - loss: 6.4273e-04 - val_loss: 5.7258e-04\n",
      "Epoch 34/300\n",
      "3/3 - 0s - loss: 6.1219e-04 - val_loss: 6.0234e-04\n",
      "Epoch 35/300\n",
      "3/3 - 0s - loss: 6.2442e-04 - val_loss: 5.6216e-04\n",
      "Epoch 36/300\n",
      "3/3 - 0s - loss: 5.9581e-04 - val_loss: 5.3601e-04\n",
      "Epoch 37/300\n",
      "3/3 - 0s - loss: 5.5500e-04 - val_loss: 5.2875e-04\n",
      "Epoch 38/300\n",
      "3/3 - 0s - loss: 5.4684e-04 - val_loss: 5.2934e-04\n",
      "Epoch 39/300\n",
      "3/3 - 0s - loss: 5.5174e-04 - val_loss: 5.4299e-04\n",
      "Epoch 40/300\n",
      "3/3 - 0s - loss: 5.5112e-04 - val_loss: 5.1667e-04\n",
      "Epoch 41/300\n",
      "3/3 - 0s - loss: 5.5664e-04 - val_loss: 5.1503e-04\n",
      "Epoch 42/300\n",
      "3/3 - 0s - loss: 5.2984e-04 - val_loss: 4.9453e-04\n",
      "Epoch 43/300\n",
      "3/3 - 0s - loss: 5.3451e-04 - val_loss: 4.8558e-04\n",
      "Epoch 44/300\n",
      "3/3 - 0s - loss: 5.3945e-04 - val_loss: 4.8103e-04\n",
      "Epoch 45/300\n",
      "3/3 - 0s - loss: 5.4902e-04 - val_loss: 4.8723e-04\n",
      "Epoch 46/300\n",
      "3/3 - 0s - loss: 5.4086e-04 - val_loss: 4.7880e-04\n",
      "Epoch 47/300\n",
      "3/3 - 0s - loss: 5.6773e-04 - val_loss: 4.7564e-04\n",
      "Epoch 48/300\n",
      "3/3 - 0s - loss: 5.4596e-04 - val_loss: 4.8155e-04\n",
      "Epoch 49/300\n",
      "3/3 - 0s - loss: 5.3159e-04 - val_loss: 4.8507e-04\n",
      "Epoch 50/300\n",
      "3/3 - 0s - loss: 4.9308e-04 - val_loss: 5.0854e-04\n",
      "Epoch 51/300\n",
      "3/3 - 0s - loss: 4.6917e-04 - val_loss: 5.6140e-04\n",
      "Epoch 52/300\n",
      "3/3 - 0s - loss: 4.8255e-04 - val_loss: 5.6663e-04\n",
      "Epoch 53/300\n",
      "3/3 - 0s - loss: 5.0673e-04 - val_loss: 4.6489e-04\n",
      "Epoch 54/300\n",
      "3/3 - 0s - loss: 4.5604e-04 - val_loss: 4.6137e-04\n",
      "Epoch 55/300\n",
      "3/3 - 0s - loss: 4.4585e-04 - val_loss: 4.4937e-04\n",
      "Epoch 56/300\n",
      "3/3 - 0s - loss: 4.5125e-04 - val_loss: 4.4732e-04\n",
      "Epoch 57/300\n",
      "3/3 - 0s - loss: 4.4559e-04 - val_loss: 4.4687e-04\n",
      "Epoch 58/300\n",
      "3/3 - 0s - loss: 4.3336e-04 - val_loss: 4.4017e-04\n",
      "Epoch 59/300\n",
      "3/3 - 0s - loss: 4.1859e-04 - val_loss: 4.4716e-04\n",
      "Epoch 60/300\n",
      "3/3 - 0s - loss: 4.2464e-04 - val_loss: 4.3660e-04\n",
      "Epoch 61/300\n",
      "3/3 - 0s - loss: 4.1987e-04 - val_loss: 4.3323e-04\n",
      "Epoch 62/300\n",
      "3/3 - 0s - loss: 4.0691e-04 - val_loss: 4.3066e-04\n",
      "Epoch 63/300\n",
      "3/3 - 0s - loss: 4.0167e-04 - val_loss: 4.2393e-04\n",
      "Epoch 64/300\n",
      "3/3 - 0s - loss: 3.9409e-04 - val_loss: 4.2478e-04\n",
      "Epoch 65/300\n",
      "3/3 - 0s - loss: 4.0029e-04 - val_loss: 4.2575e-04\n",
      "Epoch 66/300\n",
      "3/3 - 0s - loss: 4.0855e-04 - val_loss: 4.2107e-04\n",
      "Epoch 67/300\n",
      "3/3 - 0s - loss: 3.8689e-04 - val_loss: 4.1880e-04\n",
      "Epoch 68/300\n",
      "3/3 - 0s - loss: 4.2269e-04 - val_loss: 4.1032e-04\n",
      "Epoch 69/300\n",
      "3/3 - 0s - loss: 3.7888e-04 - val_loss: 4.0516e-04\n",
      "Epoch 70/300\n",
      "3/3 - 0s - loss: 3.7350e-04 - val_loss: 4.0099e-04\n",
      "Epoch 71/300\n",
      "3/3 - 0s - loss: 3.7826e-04 - val_loss: 4.0179e-04\n",
      "Epoch 72/300\n",
      "3/3 - 0s - loss: 3.6944e-04 - val_loss: 3.9566e-04\n",
      "Epoch 73/300\n",
      "3/3 - 0s - loss: 3.6478e-04 - val_loss: 3.9374e-04\n",
      "Epoch 74/300\n",
      "3/3 - 0s - loss: 3.6645e-04 - val_loss: 3.9339e-04\n",
      "Epoch 75/300\n",
      "3/3 - 0s - loss: 3.6840e-04 - val_loss: 3.9441e-04\n",
      "Epoch 76/300\n",
      "3/3 - 0s - loss: 3.6215e-04 - val_loss: 3.8460e-04\n",
      "Epoch 77/300\n",
      "3/3 - 0s - loss: 3.6220e-04 - val_loss: 3.9748e-04\n",
      "Epoch 78/300\n",
      "3/3 - 0s - loss: 3.6369e-04 - val_loss: 3.7833e-04\n",
      "Epoch 79/300\n",
      "3/3 - 0s - loss: 3.5069e-04 - val_loss: 3.7985e-04\n",
      "Epoch 80/300\n",
      "3/3 - 0s - loss: 3.5767e-04 - val_loss: 4.0372e-04\n",
      "Epoch 81/300\n",
      "3/3 - 0s - loss: 3.6852e-04 - val_loss: 4.0962e-04\n",
      "Epoch 82/300\n",
      "3/3 - 0s - loss: 3.9116e-04 - val_loss: 4.3852e-04\n",
      "Epoch 83/300\n",
      "3/3 - 0s - loss: 3.8077e-04 - val_loss: 3.7826e-04\n",
      "Epoch 84/300\n",
      "3/3 - 0s - loss: 3.4110e-04 - val_loss: 3.8213e-04\n",
      "Epoch 85/300\n",
      "3/3 - 0s - loss: 3.4454e-04 - val_loss: 3.6285e-04\n",
      "Epoch 86/300\n",
      "3/3 - 0s - loss: 3.3409e-04 - val_loss: 3.7235e-04\n",
      "Epoch 87/300\n",
      "3/3 - 0s - loss: 3.3077e-04 - val_loss: 3.6482e-04\n",
      "Epoch 88/300\n",
      "3/3 - 0s - loss: 3.3409e-04 - val_loss: 3.6912e-04\n",
      "Epoch 89/300\n",
      "3/3 - 0s - loss: 3.2841e-04 - val_loss: 3.5926e-04\n",
      "Epoch 90/300\n",
      "3/3 - 0s - loss: 3.3499e-04 - val_loss: 3.5377e-04\n",
      "Epoch 91/300\n",
      "3/3 - 0s - loss: 3.3055e-04 - val_loss: 3.5550e-04\n",
      "Epoch 92/300\n",
      "3/3 - 0s - loss: 3.2280e-04 - val_loss: 3.5095e-04\n",
      "Epoch 93/300\n",
      "3/3 - 0s - loss: 3.2151e-04 - val_loss: 3.4658e-04\n",
      "Epoch 94/300\n",
      "3/3 - 0s - loss: 3.1482e-04 - val_loss: 3.4514e-04\n",
      "Epoch 95/300\n",
      "3/3 - 0s - loss: 3.1307e-04 - val_loss: 3.3981e-04\n",
      "Epoch 96/300\n",
      "3/3 - 0s - loss: 3.1929e-04 - val_loss: 3.3819e-04\n",
      "Epoch 97/300\n",
      "3/3 - 0s - loss: 3.1026e-04 - val_loss: 3.4707e-04\n",
      "Epoch 98/300\n",
      "3/3 - 0s - loss: 3.1698e-04 - val_loss: 3.3703e-04\n",
      "Epoch 99/300\n",
      "3/3 - 0s - loss: 3.1200e-04 - val_loss: 3.4458e-04\n",
      "Epoch 100/300\n",
      "3/3 - 0s - loss: 3.1912e-04 - val_loss: 3.4473e-04\n",
      "Epoch 101/300\n",
      "3/3 - 0s - loss: 3.2510e-04 - val_loss: 3.4535e-04\n",
      "Epoch 102/300\n",
      "3/3 - 0s - loss: 3.5086e-04 - val_loss: 3.9246e-04\n",
      "Epoch 103/300\n",
      "3/3 - 0s - loss: 3.4768e-04 - val_loss: 4.2652e-04\n",
      "Epoch 104/300\n",
      "3/3 - 0s - loss: 3.5902e-04 - val_loss: 3.8167e-04\n",
      "Epoch 105/300\n",
      "3/3 - 0s - loss: 3.1458e-04 - val_loss: 3.6047e-04\n",
      "Epoch 106/300\n",
      "3/3 - 0s - loss: 3.0785e-04 - val_loss: 3.6503e-04\n",
      "Epoch 107/300\n",
      "3/3 - 0s - loss: 3.3106e-04 - val_loss: 3.1534e-04\n",
      "Epoch 108/300\n",
      "3/3 - 0s - loss: 3.3068e-04 - val_loss: 3.4394e-04\n",
      "Epoch 109/300\n",
      "3/3 - 0s - loss: 3.2817e-04 - val_loss: 3.8140e-04\n",
      "Epoch 110/300\n",
      "3/3 - 0s - loss: 3.0882e-04 - val_loss: 4.0152e-04\n",
      "Epoch 111/300\n",
      "3/3 - 0s - loss: 3.2850e-04 - val_loss: 4.5861e-04\n",
      "Epoch 112/300\n",
      "3/3 - 0s - loss: 3.7321e-04 - val_loss: 4.2871e-04\n",
      "Epoch 113/300\n",
      "3/3 - 0s - loss: 4.1143e-04 - val_loss: 3.7086e-04\n",
      "Epoch 114/300\n",
      "3/3 - 0s - loss: 3.2013e-04 - val_loss: 3.1440e-04\n",
      "Epoch 115/300\n",
      "3/3 - 0s - loss: 3.2224e-04 - val_loss: 3.0302e-04\n",
      "Epoch 116/300\n",
      "3/3 - 0s - loss: 3.0127e-04 - val_loss: 3.2586e-04\n",
      "Epoch 117/300\n",
      "3/3 - 0s - loss: 2.9264e-04 - val_loss: 3.2196e-04\n",
      "Epoch 118/300\n",
      "3/3 - 0s - loss: 3.0228e-04 - val_loss: 4.5439e-04\n",
      "Epoch 119/300\n",
      "3/3 - 0s - loss: 3.6573e-04 - val_loss: 3.5966e-04\n",
      "Epoch 120/300\n",
      "3/3 - 0s - loss: 2.9248e-04 - val_loss: 3.9438e-04\n",
      "Epoch 121/300\n",
      "3/3 - 0s - loss: 3.3791e-04 - val_loss: 3.0103e-04\n",
      "Epoch 122/300\n",
      "3/3 - 0s - loss: 3.2621e-04 - val_loss: 2.9334e-04\n",
      "Epoch 123/300\n",
      "3/3 - 0s - loss: 3.1752e-04 - val_loss: 3.6935e-04\n",
      "Epoch 124/300\n",
      "3/3 - 0s - loss: 3.5198e-04 - val_loss: 3.8143e-04\n",
      "Epoch 125/300\n",
      "3/3 - 0s - loss: 3.5194e-04 - val_loss: 4.3187e-04\n",
      "Epoch 126/300\n",
      "3/3 - 0s - loss: 3.4739e-04 - val_loss: 3.2419e-04\n",
      "Epoch 127/300\n",
      "3/3 - 0s - loss: 2.9610e-04 - val_loss: 3.4015e-04\n",
      "Epoch 128/300\n",
      "3/3 - 0s - loss: 3.1515e-04 - val_loss: 2.8817e-04\n",
      "Epoch 129/300\n",
      "3/3 - 0s - loss: 3.0133e-04 - val_loss: 2.9302e-04\n",
      "Epoch 130/300\n",
      "3/3 - 0s - loss: 2.9007e-04 - val_loss: 3.1876e-04\n",
      "Epoch 131/300\n",
      "3/3 - 0s - loss: 2.8333e-04 - val_loss: 2.8272e-04\n",
      "Epoch 132/300\n",
      "3/3 - 0s - loss: 2.5995e-04 - val_loss: 2.9354e-04\n",
      "Epoch 133/300\n",
      "3/3 - 0s - loss: 3.0014e-04 - val_loss: 3.0389e-04\n",
      "Epoch 134/300\n",
      "3/3 - 0s - loss: 2.7290e-04 - val_loss: 2.9575e-04\n",
      "Epoch 135/300\n",
      "3/3 - 0s - loss: 2.6981e-04 - val_loss: 2.8452e-04\n",
      "Epoch 136/300\n",
      "3/3 - 0s - loss: 2.5423e-04 - val_loss: 2.7556e-04\n",
      "Epoch 137/300\n",
      "3/3 - 0s - loss: 2.5472e-04 - val_loss: 2.7463e-04\n",
      "Epoch 138/300\n",
      "3/3 - 0s - loss: 2.6125e-04 - val_loss: 2.8759e-04\n",
      "Epoch 139/300\n",
      "3/3 - 0s - loss: 2.5818e-04 - val_loss: 2.7177e-04\n",
      "Epoch 140/300\n",
      "3/3 - 0s - loss: 2.6747e-04 - val_loss: 2.8318e-04\n",
      "Epoch 141/300\n",
      "3/3 - 0s - loss: 2.6817e-04 - val_loss: 3.3844e-04\n",
      "Epoch 142/300\n",
      "3/3 - 0s - loss: 2.9462e-04 - val_loss: 2.7803e-04\n",
      "Epoch 143/300\n",
      "3/3 - 0s - loss: 2.5212e-04 - val_loss: 2.7657e-04\n",
      "Epoch 144/300\n",
      "3/3 - 0s - loss: 2.5150e-04 - val_loss: 2.6480e-04\n",
      "Epoch 145/300\n",
      "3/3 - 0s - loss: 2.4829e-04 - val_loss: 2.6971e-04\n",
      "Epoch 146/300\n",
      "3/3 - 0s - loss: 2.4358e-04 - val_loss: 2.6179e-04\n",
      "Epoch 147/300\n",
      "3/3 - 0s - loss: 2.4182e-04 - val_loss: 2.6593e-04\n",
      "Epoch 148/300\n",
      "3/3 - 0s - loss: 2.5282e-04 - val_loss: 2.6537e-04\n",
      "Epoch 149/300\n",
      "3/3 - 0s - loss: 2.4258e-04 - val_loss: 3.0778e-04\n",
      "Epoch 150/300\n",
      "3/3 - 0s - loss: 2.6174e-04 - val_loss: 2.6547e-04\n",
      "Epoch 151/300\n",
      "3/3 - 0s - loss: 2.5523e-04 - val_loss: 2.5529e-04\n",
      "Epoch 152/300\n",
      "3/3 - 0s - loss: 2.4064e-04 - val_loss: 2.5668e-04\n",
      "Epoch 153/300\n",
      "3/3 - 0s - loss: 2.3870e-04 - val_loss: 2.5952e-04\n",
      "Epoch 154/300\n",
      "3/3 - 0s - loss: 2.3680e-04 - val_loss: 2.5905e-04\n",
      "Epoch 155/300\n",
      "3/3 - 0s - loss: 2.3843e-04 - val_loss: 2.6258e-04\n",
      "Epoch 156/300\n",
      "3/3 - 0s - loss: 2.3025e-04 - val_loss: 2.9599e-04\n",
      "Epoch 157/300\n",
      "3/3 - 0s - loss: 2.9480e-04 - val_loss: 2.5632e-04\n",
      "Epoch 158/300\n",
      "3/3 - 0s - loss: 2.3902e-04 - val_loss: 2.5188e-04\n",
      "Epoch 159/300\n",
      "3/3 - 0s - loss: 2.6736e-04 - val_loss: 2.5037e-04\n",
      "Epoch 160/300\n",
      "3/3 - 0s - loss: 2.3071e-04 - val_loss: 2.8163e-04\n",
      "Epoch 161/300\n",
      "3/3 - 0s - loss: 2.4005e-04 - val_loss: 3.2756e-04\n",
      "Epoch 162/300\n",
      "3/3 - 0s - loss: 2.3614e-04 - val_loss: 4.8911e-04\n",
      "Epoch 163/300\n",
      "3/3 - 0s - loss: 4.0318e-04 - val_loss: 3.8249e-04\n",
      "Epoch 164/300\n",
      "3/3 - 0s - loss: 2.9006e-04 - val_loss: 3.1240e-04\n",
      "Epoch 165/300\n",
      "3/3 - 0s - loss: 2.5790e-04 - val_loss: 2.5882e-04\n",
      "Epoch 166/300\n",
      "3/3 - 0s - loss: 2.8336e-04 - val_loss: 2.5034e-04\n",
      "Epoch 167/300\n",
      "3/3 - 0s - loss: 3.1151e-04 - val_loss: 3.0370e-04\n",
      "Epoch 168/300\n",
      "3/3 - 0s - loss: 3.0930e-04 - val_loss: 2.9837e-04\n",
      "Epoch 169/300\n",
      "3/3 - 0s - loss: 2.6660e-04 - val_loss: 3.2873e-04\n",
      "Epoch 170/300\n",
      "3/3 - 0s - loss: 2.3987e-04 - val_loss: 3.0955e-04\n",
      "Epoch 171/300\n",
      "3/3 - 0s - loss: 2.7691e-04 - val_loss: 3.0776e-04\n",
      "Epoch 172/300\n",
      "3/3 - 0s - loss: 2.6199e-04 - val_loss: 2.5844e-04\n",
      "Epoch 173/300\n",
      "3/3 - 0s - loss: 2.8333e-04 - val_loss: 2.4814e-04\n",
      "Epoch 174/300\n",
      "3/3 - 0s - loss: 3.0849e-04 - val_loss: 3.5301e-04\n",
      "Epoch 175/300\n",
      "3/3 - 0s - loss: 2.8849e-04 - val_loss: 4.2575e-04\n",
      "Epoch 176/300\n",
      "3/3 - 0s - loss: 3.5725e-04 - val_loss: 5.1944e-04\n",
      "Epoch 177/300\n",
      "3/3 - 0s - loss: 3.1697e-04 - val_loss: 4.3006e-04\n",
      "Epoch 178/300\n",
      "3/3 - 0s - loss: 3.3530e-04 - val_loss: 4.7126e-04\n",
      "Epoch 179/300\n",
      "3/3 - 0s - loss: 4.2629e-04 - val_loss: 2.4779e-04\n",
      "Epoch 180/300\n",
      "3/3 - 0s - loss: 2.7405e-04 - val_loss: 2.4837e-04\n",
      "Epoch 181/300\n",
      "3/3 - 0s - loss: 2.9533e-04 - val_loss: 2.5912e-04\n",
      "Epoch 182/300\n",
      "3/3 - 0s - loss: 2.6480e-04 - val_loss: 2.5448e-04\n",
      "Epoch 183/300\n",
      "3/3 - 0s - loss: 2.4854e-04 - val_loss: 2.7969e-04\n",
      "Epoch 184/300\n",
      "3/3 - 0s - loss: 2.4017e-04 - val_loss: 2.6088e-04\n",
      "Epoch 185/300\n",
      "3/3 - 0s - loss: 2.4732e-04 - val_loss: 3.1797e-04\n",
      "Epoch 186/300\n",
      "3/3 - 0s - loss: 2.6398e-04 - val_loss: 2.6086e-04\n",
      "Epoch 187/300\n",
      "3/3 - 0s - loss: 2.6613e-04 - val_loss: 2.3798e-04\n",
      "Epoch 188/300\n",
      "3/3 - 0s - loss: 2.1222e-04 - val_loss: 2.3551e-04\n",
      "Epoch 189/300\n",
      "3/3 - 0s - loss: 2.2094e-04 - val_loss: 2.3176e-04\n",
      "Epoch 190/300\n",
      "3/3 - 0s - loss: 2.1680e-04 - val_loss: 2.2779e-04\n",
      "Epoch 191/300\n",
      "3/3 - 0s - loss: 2.2756e-04 - val_loss: 2.4464e-04\n",
      "Epoch 192/300\n",
      "3/3 - 0s - loss: 2.4311e-04 - val_loss: 2.6990e-04\n",
      "Epoch 193/300\n",
      "3/3 - 0s - loss: 2.4334e-04 - val_loss: 2.5238e-04\n",
      "Epoch 194/300\n",
      "3/3 - 0s - loss: 2.2754e-04 - val_loss: 2.4033e-04\n",
      "Epoch 195/300\n",
      "3/3 - 0s - loss: 2.1455e-04 - val_loss: 2.2463e-04\n",
      "Epoch 196/300\n",
      "3/3 - 0s - loss: 2.2138e-04 - val_loss: 2.2240e-04\n",
      "Epoch 197/300\n",
      "3/3 - 0s - loss: 2.2174e-04 - val_loss: 2.3727e-04\n",
      "Epoch 198/300\n",
      "3/3 - 0s - loss: 2.2358e-04 - val_loss: 2.2986e-04\n",
      "Epoch 199/300\n",
      "3/3 - 0s - loss: 2.2286e-04 - val_loss: 2.6233e-04\n",
      "Epoch 200/300\n",
      "3/3 - 0s - loss: 2.1665e-04 - val_loss: 2.4378e-04\n",
      "Epoch 201/300\n",
      "3/3 - 0s - loss: 2.2431e-04 - val_loss: 2.2614e-04\n",
      "Epoch 202/300\n",
      "3/3 - 0s - loss: 2.0143e-04 - val_loss: 2.1838e-04\n",
      "Epoch 203/300\n",
      "3/3 - 0s - loss: 2.0937e-04 - val_loss: 2.1828e-04\n",
      "Epoch 204/300\n",
      "3/3 - 0s - loss: 2.0212e-04 - val_loss: 2.1451e-04\n",
      "Epoch 205/300\n",
      "3/3 - 0s - loss: 2.0585e-04 - val_loss: 2.2708e-04\n",
      "Epoch 206/300\n",
      "3/3 - 0s - loss: 2.0250e-04 - val_loss: 2.2194e-04\n",
      "Epoch 207/300\n",
      "3/3 - 0s - loss: 2.0299e-04 - val_loss: 2.1736e-04\n",
      "Epoch 208/300\n",
      "3/3 - 0s - loss: 2.1118e-04 - val_loss: 2.1567e-04\n",
      "Epoch 209/300\n",
      "3/3 - 0s - loss: 2.0701e-04 - val_loss: 2.1915e-04\n",
      "Epoch 210/300\n",
      "3/3 - 0s - loss: 2.0322e-04 - val_loss: 2.1825e-04\n",
      "Epoch 211/300\n",
      "3/3 - 0s - loss: 1.9878e-04 - val_loss: 2.1595e-04\n",
      "Epoch 212/300\n",
      "3/3 - 0s - loss: 1.9716e-04 - val_loss: 2.1119e-04\n",
      "Epoch 213/300\n",
      "3/3 - 0s - loss: 1.9408e-04 - val_loss: 2.1526e-04\n",
      "Epoch 214/300\n",
      "3/3 - 0s - loss: 2.0716e-04 - val_loss: 2.2999e-04\n",
      "Epoch 215/300\n",
      "3/3 - 0s - loss: 2.0926e-04 - val_loss: 2.3061e-04\n",
      "Epoch 216/300\n",
      "3/3 - 0s - loss: 2.0744e-04 - val_loss: 2.9831e-04\n",
      "Epoch 217/300\n",
      "3/3 - 0s - loss: 2.4285e-04 - val_loss: 2.4972e-04\n",
      "Epoch 218/300\n",
      "3/3 - 0s - loss: 2.0673e-04 - val_loss: 2.3515e-04\n",
      "Epoch 219/300\n",
      "3/3 - 0s - loss: 2.0272e-04 - val_loss: 2.0734e-04\n",
      "Epoch 220/300\n",
      "3/3 - 0s - loss: 1.9559e-04 - val_loss: 2.0603e-04\n",
      "Epoch 221/300\n",
      "3/3 - 0s - loss: 2.0158e-04 - val_loss: 2.5244e-04\n",
      "Epoch 222/300\n",
      "3/3 - 0s - loss: 2.1697e-04 - val_loss: 2.3761e-04\n",
      "Epoch 223/300\n",
      "3/3 - 0s - loss: 2.1140e-04 - val_loss: 2.4716e-04\n",
      "Epoch 224/300\n",
      "3/3 - 0s - loss: 1.9911e-04 - val_loss: 2.4720e-04\n",
      "Epoch 225/300\n",
      "3/3 - 0s - loss: 2.2839e-04 - val_loss: 2.2323e-04\n",
      "Epoch 226/300\n",
      "3/3 - 0s - loss: 2.4337e-04 - val_loss: 2.0857e-04\n",
      "Epoch 227/300\n",
      "3/3 - 0s - loss: 1.9499e-04 - val_loss: 2.0444e-04\n",
      "Epoch 228/300\n",
      "3/3 - 0s - loss: 1.9328e-04 - val_loss: 2.0954e-04\n",
      "Epoch 229/300\n",
      "3/3 - 0s - loss: 1.9730e-04 - val_loss: 2.0679e-04\n",
      "Epoch 230/300\n",
      "3/3 - 0s - loss: 1.8779e-04 - val_loss: 2.0701e-04\n",
      "Epoch 231/300\n",
      "3/3 - 0s - loss: 1.9105e-04 - val_loss: 2.0314e-04\n",
      "Epoch 232/300\n",
      "3/3 - 0s - loss: 1.8460e-04 - val_loss: 1.9941e-04\n",
      "Epoch 233/300\n",
      "3/3 - 0s - loss: 1.8826e-04 - val_loss: 2.1509e-04\n",
      "Epoch 234/300\n",
      "3/3 - 0s - loss: 1.9326e-04 - val_loss: 2.0106e-04\n",
      "Epoch 235/300\n",
      "3/3 - 0s - loss: 1.8840e-04 - val_loss: 2.0191e-04\n",
      "Epoch 236/300\n",
      "3/3 - 0s - loss: 2.3059e-04 - val_loss: 2.6005e-04\n",
      "Epoch 237/300\n",
      "3/3 - 0s - loss: 2.2426e-04 - val_loss: 2.8834e-04\n",
      "Epoch 238/300\n",
      "3/3 - 0s - loss: 2.1661e-04 - val_loss: 2.6111e-04\n",
      "Epoch 239/300\n",
      "3/3 - 0s - loss: 2.2444e-04 - val_loss: 2.2469e-04\n",
      "Epoch 240/300\n",
      "3/3 - 0s - loss: 2.1164e-04 - val_loss: 2.0124e-04\n",
      "Epoch 241/300\n",
      "3/3 - 0s - loss: 1.9931e-04 - val_loss: 2.0685e-04\n",
      "Epoch 242/300\n",
      "3/3 - 0s - loss: 1.9617e-04 - val_loss: 2.1235e-04\n",
      "Epoch 243/300\n",
      "3/3 - 0s - loss: 1.9877e-04 - val_loss: 2.5236e-04\n",
      "Epoch 244/300\n",
      "3/3 - 0s - loss: 2.1178e-04 - val_loss: 2.5076e-04\n",
      "Epoch 245/300\n",
      "3/3 - 0s - loss: 2.0829e-04 - val_loss: 2.4881e-04\n",
      "Epoch 246/300\n",
      "3/3 - 0s - loss: 2.1279e-04 - val_loss: 2.0562e-04\n",
      "Epoch 247/300\n",
      "3/3 - 0s - loss: 2.0518e-04 - val_loss: 1.9666e-04\n",
      "Epoch 248/300\n",
      "3/3 - 0s - loss: 1.8215e-04 - val_loss: 1.9122e-04\n",
      "Epoch 249/300\n",
      "3/3 - 0s - loss: 1.8788e-04 - val_loss: 2.0289e-04\n",
      "Epoch 250/300\n",
      "3/3 - 0s - loss: 1.8780e-04 - val_loss: 2.2000e-04\n",
      "Epoch 251/300\n",
      "3/3 - 0s - loss: 1.8675e-04 - val_loss: 2.1344e-04\n",
      "Epoch 252/300\n",
      "3/3 - 0s - loss: 2.0802e-04 - val_loss: 2.6724e-04\n",
      "Epoch 253/300\n",
      "3/3 - 0s - loss: 2.0697e-04 - val_loss: 2.1709e-04\n",
      "Epoch 254/300\n",
      "3/3 - 0s - loss: 1.7908e-04 - val_loss: 2.1942e-04\n",
      "Epoch 255/300\n",
      "3/3 - 0s - loss: 1.8707e-04 - val_loss: 2.2862e-04\n",
      "Epoch 256/300\n",
      "3/3 - 0s - loss: 2.2650e-04 - val_loss: 1.9037e-04\n",
      "Epoch 257/300\n",
      "3/3 - 0s - loss: 1.9013e-04 - val_loss: 1.9695e-04\n",
      "Epoch 258/300\n",
      "3/3 - 0s - loss: 2.0239e-04 - val_loss: 2.1624e-04\n",
      "Epoch 259/300\n",
      "3/3 - 0s - loss: 1.8454e-04 - val_loss: 2.0209e-04\n",
      "Epoch 260/300\n",
      "3/3 - 0s - loss: 1.7768e-04 - val_loss: 1.9142e-04\n",
      "Epoch 261/300\n",
      "3/3 - 0s - loss: 1.7099e-04 - val_loss: 1.8860e-04\n",
      "Epoch 262/300\n",
      "3/3 - 0s - loss: 1.6750e-04 - val_loss: 1.8903e-04\n",
      "Epoch 263/300\n",
      "3/3 - 0s - loss: 1.6877e-04 - val_loss: 1.9525e-04\n",
      "Epoch 264/300\n",
      "3/3 - 0s - loss: 1.8699e-04 - val_loss: 2.2876e-04\n",
      "Epoch 265/300\n",
      "3/3 - 0s - loss: 1.9885e-04 - val_loss: 1.9353e-04\n",
      "Epoch 266/300\n",
      "3/3 - 0s - loss: 1.8464e-04 - val_loss: 1.8550e-04\n",
      "Epoch 267/300\n",
      "3/3 - 0s - loss: 1.7877e-04 - val_loss: 1.9431e-04\n",
      "Epoch 268/300\n",
      "3/3 - 0s - loss: 1.8699e-04 - val_loss: 2.1184e-04\n",
      "Epoch 269/300\n",
      "3/3 - 0s - loss: 1.8069e-04 - val_loss: 1.9911e-04\n",
      "Epoch 270/300\n",
      "3/3 - 0s - loss: 1.6785e-04 - val_loss: 2.2424e-04\n",
      "Epoch 271/300\n",
      "3/3 - 0s - loss: 2.0308e-04 - val_loss: 1.8834e-04\n",
      "Epoch 272/300\n",
      "3/3 - 0s - loss: 1.7782e-04 - val_loss: 1.8548e-04\n",
      "Epoch 273/300\n",
      "3/3 - 0s - loss: 1.8704e-04 - val_loss: 1.9762e-04\n",
      "Epoch 274/300\n",
      "3/3 - 0s - loss: 1.8618e-04 - val_loss: 1.9812e-04\n",
      "Epoch 275/300\n",
      "3/3 - 0s - loss: 1.8080e-04 - val_loss: 1.8264e-04\n",
      "Epoch 276/300\n",
      "3/3 - 0s - loss: 1.7336e-04 - val_loss: 1.8874e-04\n",
      "Epoch 277/300\n",
      "3/3 - 0s - loss: 1.7408e-04 - val_loss: 2.1978e-04\n",
      "Epoch 278/300\n",
      "3/3 - 0s - loss: 1.8924e-04 - val_loss: 2.8211e-04\n",
      "Epoch 279/300\n",
      "3/3 - 0s - loss: 2.1666e-04 - val_loss: 3.3145e-04\n",
      "Epoch 280/300\n",
      "3/3 - 0s - loss: 2.3083e-04 - val_loss: 3.8227e-04\n",
      "Epoch 281/300\n",
      "3/3 - 0s - loss: 2.9925e-04 - val_loss: 2.2467e-04\n",
      "Epoch 282/300\n",
      "3/3 - 0s - loss: 3.0026e-04 - val_loss: 1.8343e-04\n",
      "Epoch 283/300\n",
      "3/3 - 0s - loss: 2.5655e-04 - val_loss: 2.1952e-04\n",
      "Epoch 284/300\n",
      "3/3 - 0s - loss: 2.2745e-04 - val_loss: 3.2368e-04\n",
      "Epoch 285/300\n",
      "3/3 - 0s - loss: 2.4496e-04 - val_loss: 4.3658e-04\n",
      "Epoch 286/300\n",
      "3/3 - 0s - loss: 3.0567e-04 - val_loss: 3.6121e-04\n",
      "Epoch 287/300\n",
      "3/3 - 0s - loss: 2.6085e-04 - val_loss: 2.6261e-04\n",
      "Epoch 288/300\n",
      "3/3 - 0s - loss: 1.9460e-04 - val_loss: 2.3601e-04\n",
      "Epoch 289/300\n",
      "3/3 - 0s - loss: 2.3353e-04 - val_loss: 1.8302e-04\n",
      "Epoch 290/300\n",
      "3/3 - 0s - loss: 1.9397e-04 - val_loss: 1.8202e-04\n",
      "Epoch 291/300\n",
      "3/3 - 0s - loss: 2.0730e-04 - val_loss: 2.1028e-04\n",
      "Epoch 292/300\n",
      "3/3 - 0s - loss: 2.1321e-04 - val_loss: 2.5683e-04\n",
      "Epoch 293/300\n",
      "3/3 - 0s - loss: 2.0388e-04 - val_loss: 2.5870e-04\n",
      "Epoch 294/300\n",
      "3/3 - 0s - loss: 2.0545e-04 - val_loss: 2.0948e-04\n",
      "Epoch 295/300\n",
      "3/3 - 0s - loss: 1.8005e-04 - val_loss: 1.9964e-04\n",
      "Epoch 296/300\n",
      "3/3 - 0s - loss: 1.6996e-04 - val_loss: 1.8702e-04\n",
      "Epoch 297/300\n",
      "3/3 - 0s - loss: 1.6315e-04 - val_loss: 1.8560e-04\n",
      "Epoch 298/300\n",
      "3/3 - 0s - loss: 1.9246e-04 - val_loss: 1.9053e-04\n",
      "Epoch 299/300\n",
      "3/3 - 0s - loss: 1.8314e-04 - val_loss: 1.9737e-04\n",
      "Epoch 300/300\n",
      "3/3 - 0s - loss: 1.8180e-04 - val_loss: 2.1272e-04\n"
     ]
    }
   ],
   "source": [
    "hist=train_model(X_train,y_train,ConvMod,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keras_model(dataset,model,loss,optimizer):\n",
    "    dirx = './ConvModel'\n",
    "    os.chdir(dirx)\n",
    "    json_file = open('Stocks'+'_best_model'+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics = None)\n",
    "    model.load_weights('Stocks'+'_best_model'+'.h5')\n",
    "    return model\n",
    "def evaluation(exe_time,X_test, y_test,X_train, y_train,history,model,optimizer,loss):\n",
    "    model = load_keras_model('./ConvModel',model,loss, optimizer)\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "    eval_test_loss = round(100-(test_loss*100),1)\n",
    "    eval_train_loss = round(100-(train_loss*100),1)\n",
    "    eval_average_loss = round((eval_test_loss + eval_train_loss)/2,1)\n",
    "    print(\"--- Training Report ---\")\n",
    "    #plot_loss(history)\n",
    "    print('Execution time: ',round(exe_time,2),'s')\n",
    "    print('Testing Accuracy:',eval_test_loss,'%')\n",
    "    print('Training Accuracy:',eval_train_loss,'%')\n",
    "    print('Average Network Accuracy:',eval_average_loss,'%')\n",
    "    return model,eval_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\lesap\\\\Documents\\\\GitHub\\\\ConvLSTMTradingBot\\\\ConvModel'"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Training Report ---\nExecution time:  5 s\nTesting Accuracy: 100.0 %\nTraining Accuracy: 100.0 %\nAverage Network Accuracy: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "evaled_model,eval_test_loss = evaluation(5, X_test, y_test,X_train, y_train,history=hist,model=ConvMod,optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\lesap\\\\Documents\\\\GitHub\\\\ConvolutionalTradingBotTensorTrade'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data_len=1500\n",
    "end = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "start = datetime.datetime.strptime(end, '%Y-%m-%d') - datetime.timedelta(days=(data_len/0.463))\n",
    "symbol='AAPL'\n",
    "orig_dataset = yf.download(symbol,start,end)\n",
    "close = orig_dataset['Close'].values\n",
    "open_ = orig_dataset['Open'].values\n",
    "high = orig_dataset['High'].values\n",
    "low = orig_dataset['Low'].values\n",
    "\n",
    "bestMod=load_keras_model(orig_dataset,ConvMod,'mse','adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_predict(model,minmax,seq_len,n_features,n_steps,data,test_loss):\n",
    "    pred_data = data[:,0].reshape((len(data[0]),1, n_steps, n_features))\n",
    "    pred = model.predict(pred_data)[0]\n",
    "    appro_loss = list()\n",
    "    for i in range(len(pred)):\n",
    "        pred[i] = pred[i] * (minmax[i][1] - minmax[i][0]) + minmax[i][0]\n",
    "        appro_loss.append(((100-test_loss)/100) * (minmax[i][1] - minmax[i][0]))\n",
    "    return pred,appro_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = ConvMod.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.00020790912094525993"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2233, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2233"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "len(data[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2233 into shape (4,1,1500,4)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-1d393b3461cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mappro_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarket_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvMod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-6ca5ccbaaf91>\u001b[0m in \u001b[0;36mmarket_predict\u001b[1;34m(model, minmax, seq_len, n_features, n_steps, data, test_loss)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmarket_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpred_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mappro_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2233 into shape (4,1,1500,4)"
     ]
    }
   ],
   "source": [
    "pred,appro_loss = market_predict(ConvMod, minmax, 50, 4, 1500, data, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'\n",
    "API_KEY = config.api_key\n",
    "SECRET_KEY = config.secret_key\n",
    "ORDERS_URL = '{}/v2/orders'.format(BASE_URL)\n",
    "HEADERS = {'APCA-API-KEY-ID':API_KEY,'APCA-API-SECRET-KEY':SECRET_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_order(pred_price,company,test_loss,appro_loss):\n",
    "    open_price,close_price = pred_price[0],pred_price[1]\n",
    "    if open_price > close_price:\n",
    "        side = 'sell'\n",
    "    elif open_price < close_price:\n",
    "        side = 'buy'\n",
    "    if side == 'buy':\n",
    "        order = {\n",
    "            'symbol':company,\n",
    "            'qty':round(20*(test_loss/100)),\n",
    "            'type':'stop_limit',\n",
    "            'time_in_force':'day',\n",
    "            'side': 'buy',\n",
    "            'take_profit': close_price + appro_loss,\n",
    "            'stop_loss': close_price - appro_loss\n",
    "                }\n",
    "    elif side == 'sell':\n",
    "        order = {\n",
    "            'symbol':company,\n",
    "            'qty':round(20*(test_loss/100)),\n",
    "            'type':'stop_limit',\n",
    "            'time_in_force':'day',\n",
    "            'side': 'sell',\n",
    "            'take_profit':close_price - appro_loss,\n",
    "            'stop_loss':close_price + appro_loss\n",
    "                }\n",
    "    r = requests.post(ORDERS_URL, json = order,headers = HEADERS)\n",
    "    print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}